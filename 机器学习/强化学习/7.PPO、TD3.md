# 近端策略优化（PPO）
近端策略优化（Proximal Policy Optimization, PPO）是一种广泛使用的策略梯度算法，具有较好的收敛性和鲁棒性。PPO 的核心思想是在*更新策略时对策略的变化施加限制，以确保新旧策略之间的差异不会太大*，从而稳定学习过程，常用于解决*离散动作空间和连续动作空间*的强化学习问题
PPO 通过优化以下目标函数来更新策略：
$$
L ( \theta ) = \mathbb { E } \left[ \min ( r ( \theta ) A , \operatorname { clip } ( r ( \theta ) , 1 - \epsilon , 1 + \epsilon ) A ) \right]

$$

其中，r(θ) 是新旧策略的比值，A是优势函数
## 网络结构
![](https://pic2.zhimg.com/v2-1c0bdce5fe4df17df7c4a987c4f7c9b1_1440w.jpg)
一个Actor网络，一个Critic网络（V Critic）
