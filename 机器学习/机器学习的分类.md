# 按学习风格分类
1. **监督学习**：输入数据被称为训练数据，每次都有已知的标签或结果，如分类、回归。例：*逻辑回归、反向传播神经网络*
2. **无监督学习**：输入数据没有标记或结果，通过推到输入数据中存在的结构来准备模型，可能是为了提取一般规则，如聚类、降维、关联规则学习。例：*Apriori算法和K-Means*
3. **半监督学习**：输入数据是标记和未标记示例混合的，存在期望的预测问题，但要求模型必须学习结构来组织数据并预测，如分类、回归。示例是*其他算法的扩展*，具体如图像分类领域的半监督学习方法，因为有大量数据集，但标记样本很少
# 按相似性分组
1. **回归算法**：对变量之间的关系进行建模，使用模型预测中的误差度量进行迭代细化。例：*最小二乘回归（OLSR）、线性回归、逻辑回归、逐步回归、多元自适应回归样条（MARS）、局部估计散点图平滑（LOESS）*
2. **基于实例的算法**：基于实例的学习模型是一个决策问题，包含被认为对模型重要的训练数据的示例或实例，通过建立示例数据的数据库，并使用相似性度量新数据与数据库进行比较，以便找到最佳匹配，因此又称为“赢家通吃”方法、基于记忆的学习。例：*k-最近邻（kNN）、学习矢量量化（LVQ）、自组织映射（SOM）、局部加权学习（LWL）、支持向量机（SVM）*
3. **正则化算法**：对某种算法的扩展（通常是回归算法），根据模型的复杂程度对模型进行惩罚，有利于更简单更泛化的模型。例：*岭回归、最小绝对收缩和选择算子（LASSO）、弹性网络、最小角回归（LARS）*
4. **决策树算法**：根据数据中属性的实际值构建决策模型，决策在树结构中分叉，直到针对给定记录做出预测决策，在分类和回归问题的数据上进行训练，决策树通常快速准确。例：*分类回归树（CART）、迭代二分法3（ID3）、C4.5和C5.0、卡方自动交互检测（CHAID）、决策树桩、M5、条件决策树*
5. **贝叶斯算法**：明确应用贝叶斯定理的方法，如分类和回归。例：*朴素贝叶斯、高斯朴素贝叶斯、多项式朴素贝叶斯、平均单依赖估计量（AODE）、贝叶斯信度网络（BBN）、贝叶斯网络（BN）*
6. **聚类算法**：描述问题的类别和方法的类别，通常基于质心和层次的建模方法来组织，使用数据中的固有结构来组织成具有最大共性的组。例：*k-Means、k-Medians、期望最大化（EM）、层次聚类*
7. 关联规则学习算法：提取最能解释数据中变量之间观察到的关系的规则。例：Apriori算法、Eclat算法
8. **人工神经网络算法**：受生物神经网络结构和功能启发的算法，常用于回归和分类问题的模式匹配。例：*感知器、多层感知器（MLP）、反向传播、随机梯度下降、Hopfield网络、径向基函数网络（RBFN）*
9. **深度学习算法**：是人工神经网络的现代更新，利用大量廉价的计算，设计构建更复杂的神经网络，适用于非常大的数据集，文本、图像、音频、视频等。例：*卷积神经网络（CNN）、递归神经网络（RNNs）长短期记忆网络（LSTM）、堆叠式自动编码器、深度玻尔兹曼机（DBM）、深度信念网络（DBN）*
10. **降维算法**：与聚类方法类似，寻求利用数据中的固有结构，但以无间的得方式或顺序使用较少得信息来总结或描述数据，可用于简化数据，然后在监督学习方法中使用，适用于分类、回归。例：*主成分分析（PCA）、主成分回归（PCR）、偏最小二乘回归（PLSR）、Sammon映射、多维标度（MDS）、投影寻踪、线性判别分析（LDA）、混合判别分析 (MDA)、二次判别分析（QDA）、灵活判别分析（FDA）、t分布随机邻域嵌入、一致流形逼近与投影降维（UMAP）*