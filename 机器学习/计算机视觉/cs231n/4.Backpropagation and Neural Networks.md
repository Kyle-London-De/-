
$$
L(W)=\frac{1}{N}\sum^N_{i=1} L_i(f(x_i,W),y_i)+\lambda R(W)
$$
$$
\nabla_WL(W)=\frac{1}{N}\sum^N_{i=1} \nabla_WL_i(f(x_i,W),y_i)+\lambda \nabla_WR(W)
$$
# 链式法则
$$
\frac{\partial z}{\partial x}=\frac{\partial z}{\partial y}\frac{\partial y}{\partial x}
$$
通过链式法则进行梯度的反向传播，可以将复杂的微分方程分解为简单的多个微分方程，一个计算就是一个节点，再以链式法则求取梯度
$$
f(w,z)=\frac{1}{1+e^{-(w_0x_0+w_1x_1+w_2)}}
$$
1. 可以逐步拆分成 1/x，+1，exp，* -1，+，* 等等，也可以提取出sigmoid函数 $\sigma(x)=\frac{1}{1+e^x}$，$\frac{d\sigma(x)}{dx}=\dots=(1-\sigma(x))\sigma(x)$，部分分解计算梯度，具体计算步骤是，先计算出每个节点的输入输出（前后相连，前者输出即后者输入），再根据这些值通过解析梯度公式计算梯度
2. max()函数的梯度传播，则只从选择的最大值分支传播，视为 f(x)=x ，梯度为1
3. 多元链式梯度反向传播，将多个梯度相加即可
## 例子
$$
f(x,W)=||W\cdot x||^2=\sum^n_{i=1}(W\cdot x)^2_i\quad,\quad W=\begin{bmatrix} 0.1 & 0.5 \\ -0.3 & 0.8 \end{bmatrix},x=\begin{bmatrix} 0.2 \\ 0.4 \end{bmatrix}
$$
拆分成
$$
q=W\cdot x=\begin{bmatrix} 0.22 \\ 0.26 \end{bmatrix}\quad,\quad f(q)=||q||^2=q^2_1+\dots+q^2_n=0.116
$$
1.  $\frac{\partial f}{\partial q_i}=2q_i$ ，$\nabla_q f=2q=\begin{bmatrix} 0.44 \\ 0.52 \end{bmatrix}$
2. $\frac{\partial q_k}{\partial W_{i,j}}=1_{k=i}x_j$
3. $\frac{\partial f}{\partial W_{i,j}}=\sum_k\frac{\partial f}{\partial q_k}\frac{\partial q_k}{\partial W_{i,j}}=\sum_k(2q_k)(1_{k=i}x_j)=2q_ix_j$ ， $\nabla_Wf=2q\cdot x^T=\begin{bmatrix} 0.088 & 0.176 \\ 0.104 & 0.208 \end{bmatrix}$
4. $\frac{\partial q_k}{\partial x_i}=W_{k,i}$ ， $\frac{\partial f}{\partial x_i}=\sum_k\frac{\partial f}{\partial q_k}\frac{\partial q_k}{\partial x_i}=\sum_k(2q_k)(W_{k,i})$  ， $\nabla_xf=2W^T\cdot q=\begin{bmatrix} -0.112 \\ 0.636 \end{bmatrix}$
# Neural Networks 神经网络
简单的例子，通过非线性函数将线性分类器堆叠起来，$f_1(W1\cdot x)$ ， $f_2=W_2\cdot \max(0,W1\cdot x)$ ，逐层提取特征（可以理解为第一层提取出不同颜色的车的模版，第二层再对这些模版进行加权组合）
